{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhruv\\anaconda3\\envs\\dreamdiffusion\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import ternausnet\n",
    "import ternausnet.models\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_names = os.listdir(img_dir) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx]) # Assumes masks have same filenames as images\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        if image.mode != 'RGB':\n",
    "            image = Image.merge(\"RGB\", (image, image, image))\n",
    "\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image,self.img_names[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = SegmentationDataset(img_dir='D:/study/dl/hackathon/github directory/input_image',transform=transform)\n",
    "batch_S = 1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_S, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def forward(self, input, target):\n",
    "        smooth = 1.\n",
    "        iflat = input.view(-1)\n",
    "        tflat = target.view(-1)\n",
    "        intersection = (iflat * tflat).sum()\n",
    "        \n",
    "        return 1 - ((2. * intersection + smooth) /\n",
    "              (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "class IoULoss(nn.Module):\n",
    "    def forward(self, input, target):\n",
    "        smooth = 1.\n",
    "        intersection = (input * target).sum()\n",
    "        total = (input + target).sum()\n",
    "        union = total - intersection \n",
    "        \n",
    "        return 1 - ((intersection + smooth) / (union + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhruv\\anaconda3\\envs\\dreamdiffusion\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dhruv\\anaconda3\\envs\\dreamdiffusion\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dataloader_test =  dataloader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "checkpoint = torch.load(\"D:/study/dl/hackathon/making dataset/models/model_try2_14.pth\", map_location=device)\n",
    "model = ternausnet.models.UNet11(pretrained=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = DiceLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Don't compute gradients\n",
    "    k=0\n",
    "    for images, img_names in dataloader:\n",
    "        k+=1\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        for lk in range(batch_S):\n",
    "            pk = outputs.cpu()\n",
    "            image3 = pk[lk].squeeze().detach().numpy()\n",
    "            image3 = (image3 * 255).astype('uint8')\n",
    "            cv2.imwrite(f\"D:/study/dl/hackathon/github directory/first_stage_outputs/{img_names[lk]}\",image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = SegmentationDataset(img_dir='D:/study/dl/hackathon/github directory/first_stage_outputs',transform=transform)\n",
    "batch_S = 1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_S, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test =  dataloader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_stage2 = ternausnet.models.UNet11(pretrained=True)\n",
    "model_stage2 = model_stage2.to(device)\n",
    "\n",
    "checkpoint = torch.load(\"D:/study/dl/hackathon/making dataset/models/model_stage2_dice_loss_5.pth\", map_location=device)\n",
    "model_stage2.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_stage2 = model_stage2.to(device)\n",
    "\n",
    "criterion = DiceLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stage2.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Don't compute gradients\n",
    "    k=0\n",
    "    for images, img_names in dataloader:\n",
    "        k+=1\n",
    "        images = images.to(device)\n",
    "        outputs = model_stage2(images)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        for lk in range(batch_S):\n",
    "            pk = outputs.cpu()\n",
    "            image3 = pk[lk].squeeze().detach().numpy()\n",
    "            image3 = (image3 * 255).astype('uint8')\n",
    "            cv2.imwrite(f\"D:/study/dl/hackathon/github directory/second_stage_outputs/{img_names[lk]}\",image3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreamdiffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
